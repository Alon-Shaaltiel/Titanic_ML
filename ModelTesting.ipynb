{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.315639Z",
     "start_time": "2021-09-20T11:31:26.309736Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7f13c7b09850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if str(type(sys.stdout)) == \"<class 'ipykernel.iostream.OutStream'>\":\n",
    "    saved_std = sys.stdout\n",
    "else:\n",
    "    sys.stdout = saved_std\n",
    "\n",
    "sys.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO:\n",
    "1. ~~Cleanup imports~~\n",
    "1. ~~Decide on how to impute values for each column~~\n",
    "1. ~~Use OHE and binarize the data.~~\n",
    "1. ~~Make pipelines that process the data~~\n",
    "1. Use pipelines to fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:24:08.282108Z",
     "start_time": "2021-09-20T13:24:08.277112Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#models:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#Preprocessing:\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "#Other:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:02:49.913595Z",
     "start_time": "2021-09-20T13:02:49.875700Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Deck</th>\n",
       "      <th>hasNChildren</th>\n",
       "      <th>hasCabin</th>\n",
       "      <th>has1or2sib</th>\n",
       "      <th>has3PSib</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass     Sex   Age  SibSp  Parch     Fare Embarked  Title Deck  \\\n",
       "PassengerId                                                                     \n",
       "1                 3    male  22.0      1      0   7.2500        S    Mr.    U   \n",
       "2                 1  female  38.0      1      0  71.2833        C   Mrs.    C   \n",
       "3                 3  female  26.0      0      0   7.9250        S  Miss.    U   \n",
       "4                 1  female  35.0      1      0  53.1000        S   Mrs.    C   \n",
       "5                 3    male  35.0      0      0   8.0500        S    Mr.    U   \n",
       "...             ...     ...   ...    ...    ...      ...      ...    ...  ...   \n",
       "887               2    male  27.0      0      0  13.0000        S    Mr.    U   \n",
       "888               1  female  19.0      0      0  30.0000        S  Miss.    B   \n",
       "889               3  female  15.0      1      2  23.4500        S  Miss.    U   \n",
       "890               1    male  26.0      0      0  30.0000        C    Mr.    C   \n",
       "891               3    male  32.0      0      0   7.7500        Q    Mr.    U   \n",
       "\n",
       "             hasNChildren  hasCabin  has1or2sib  has3PSib  \n",
       "PassengerId                                                \n",
       "1                       0         0           1         0  \n",
       "2                       0         1           1         0  \n",
       "3                       0         0           0         0  \n",
       "4                       0         1           1         0  \n",
       "5                       0         0           0         0  \n",
       "...                   ...       ...         ...       ...  \n",
       "887                     0         0           0         0  \n",
       "888                     0         1           0         0  \n",
       "889                     0         0           1         0  \n",
       "890                     0         1           0         0  \n",
       "891                     0         0           0         0  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Deck</th>\n",
       "      <th>hasNChildren</th>\n",
       "      <th>hasCabin</th>\n",
       "      <th>has1or2sib</th>\n",
       "      <th>has3PSib</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>U</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>C</td>\n",
       "      <td>Master.</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass     Sex   Age  SibSp  Parch      Fare Embarked    Title  \\\n",
       "PassengerId                                                                   \n",
       "892               3    male  34.5      0      0    7.8292        Q      Mr.   \n",
       "893               3  female  47.0      1      0    7.0000        S     Mrs.   \n",
       "894               2    male  62.0      0      0    9.6875        Q      Mr.   \n",
       "895               3    male  27.0      0      0    8.6625        S      Mr.   \n",
       "896               3  female  22.0      1      1   12.2875        S     Mrs.   \n",
       "...             ...     ...   ...    ...    ...       ...      ...      ...   \n",
       "1305              3    male  37.0      0      0    8.0500        S      Mr.   \n",
       "1306              1  female  39.0      0      0  108.9000        C      Mr.   \n",
       "1307              3    male  38.5      0      0    7.2500        S      Mr.   \n",
       "1308              3    male  26.0      0      0    8.0500        S      Mr.   \n",
       "1309              3    male   4.0      1      1   22.3583        C  Master.   \n",
       "\n",
       "            Deck  hasNChildren  hasCabin  has1or2sib  has3PSib  \n",
       "PassengerId                                                     \n",
       "892            U             0         0           0         0  \n",
       "893            U             0         0           1         0  \n",
       "894            U             0         0           0         0  \n",
       "895            U             0         0           0         0  \n",
       "896            U             1         0           1         0  \n",
       "...          ...           ...       ...         ...       ...  \n",
       "1305           U             0         0           0         0  \n",
       "1306           C             0         1           0         0  \n",
       "1307           U             0         0           0         0  \n",
       "1308           U             0         0           0         0  \n",
       "1309           U             0         0           1         0  \n",
       "\n",
       "[418 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_pickle('Data/modifiedData.pickle')\n",
    "test = pd.read_pickle('Data/modifiedTest.pickle')\n",
    "y = df['Survived']\n",
    "df.drop('Survived',axis=1,inplace=True)\n",
    "display(df)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age & Fare will be filled in using the appropriate distribution (as normal doesn't fit).\n",
    "# SibSp & Parch will be filled in as 0\n",
    "# Pclass & Embarked will be filled in with modal class (3rd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:16:18.218291Z",
     "start_time": "2021-09-20T13:16:18.213163Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "preSib = Pipeline(\n",
    "    [('Sib_NA', SimpleImputer(strategy='constant', fill_value=0)),('Scaler',StandardScaler())])\n",
    "\n",
    "preClass = Pipeline([('Class_NA', SimpleImputer(\n",
    "    strategy='most_frequent')), (\"OHE\", OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# handle_unknown='ignore' means that if the OHE encounters a class it doesn't recognize when transforming,\n",
    "# it'll continue instead of throwing an error.\n",
    "\n",
    "Preprocess = ColumnTransformer([('Scaler',StandardScaler(),\n",
    "                                ['Age', 'Fare', 'hasNChildren', 'hasCabin', 'has1or2sib', 'has3PSib']),\n",
    "                                ('FillNA', preSib, ['SibSp', 'Parch']), \n",
    "                                ('OHE',preClass,['Sex','Deck','Title','Embarked','Pclass'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models I'm using are those suggested [here](https://www.kaggle.com/kenjee/titanic-project-example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:16:22.554789Z",
     "start_time": "2021-09-20T13:16:22.427180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7677170296905406\n"
     ]
    }
   ],
   "source": [
    "gnb_pipe = Pipeline([('Preprocess',Preprocess),('GNB',GaussianNB())])\n",
    "cv = cross_val_score(gnb_pipe,df,y,cv=5)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:16:23.440385Z",
     "start_time": "2021-09-20T13:16:23.304925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620802209528592\n"
     ]
    }
   ],
   "source": [
    "tree_pipe = Pipeline([('Preprocess',Preprocess),('Tree',tree.DecisionTreeClassifier(random_state=7))])\n",
    "cv = cross_val_score(tree_pipe,df,y,cv=5)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:19:06.717937Z",
     "start_time": "2021-09-20T13:19:06.190978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827154604230745\n"
     ]
    }
   ],
   "source": [
    "SVC_pipe = Pipeline([('Preprocess',Preprocess),('SVC',SVC(probability = True))])\n",
    "cv = cross_val_score(SVC_pipe,df,y,cv=5)\n",
    "print(cv.mean()) # Maybe try one with less overlapping features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:26:53.889955Z",
     "start_time": "2021-09-20T13:26:53.429697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8114744837110036\n"
     ]
    }
   ],
   "source": [
    "xgb_pipe = Pipeline([('Preprocess',Preprocess),\n",
    "                     ('xgb',XGBClassifier(random_state=7,use_label_encoder=False,eval_metric='logloss'))])\n",
    "cv = cross_val_score(xgb_pipe,df,y,cv=5)\n",
    "print(cv.mean()) # Maybe try one with less overlapping features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:31:50.065904Z",
     "start_time": "2021-09-20T13:31:49.261864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8024731655263324\n"
     ]
    }
   ],
   "source": [
    "RF_pipe = Pipeline([('Preprocess',Preprocess),('RF',RandomForestClassifier(random_state=7))])\n",
    "cv = cross_val_score(RF_pipe,df,y,cv=5)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:32:53.751302Z",
     "start_time": "2021-09-20T13:32:53.569112Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7957504237022157\n"
     ]
    }
   ],
   "source": [
    "KNN_pipe = Pipeline([('Preprocess',Preprocess),('KNN',KNeighborsClassifier())])\n",
    "cv = cross_val_score(KNN_pipe,df,y,cv=5)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:35:42.598745Z",
     "start_time": "2021-09-20T13:35:42.379318Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8249325214989642\n"
     ]
    }
   ],
   "source": [
    "logreg_pipe = Pipeline([('Preprocess',Preprocess),('Logreg',LogisticRegression())])\n",
    "cv = cross_val_score(logreg_pipe,df,y,cv=5)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T13:37:35.905043Z",
     "start_time": "2021-09-20T13:37:33.558633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8327851358985626\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators = [('lr',logreg_pipe),('knn',KNN_pipe),('rf',RF_pipe),\n",
    "                                            ('svc',SVC_pipe),('xgb',xgb_pipe)], voting = 'soft')\n",
    "cv = cross_val_score(voting_clf,df,y,cv=5)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF, PROLLY GONNA DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.385995Z",
     "start_time": "2021-09-20T11:31:26.385969Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def print_best(Grid,Prints = True):\n",
    "    if Prints:\n",
    "        print(Grid.best_score_,Grid.best_params_)\n",
    "    if not Prints:\n",
    "        return [Grid.best_score_,Grid.best_params_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest_Grid_NR = GridSearchCV(Pipe_Forest,param_grid=params_Frst,scoring='f1',cv=10,return_train_score=True)\n",
    "\n",
    "Grad_Grid_NR = GridSearchCV(Pipe_Grad,param_grid=params_Grad,scoring='roc_auc',cv=10,return_train_score=True)\n",
    "\n",
    "Grad_Grid_NR.fit(data,y)\n",
    "print_best(Grad_Grid_NR)\n",
    "\n",
    "Forest_Grid_NR.fit(data,y)\n",
    "print_best(Forest_Grid_NR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest_Grid_OF = GridSearchCV(Pipe_Forest,param_grid=params_Frst,scoring='accuracy',cv=5,return_train_score=True)\n",
    "Grad_Grid_OF = GridSearchCV(Pipe_Grad,param_grid=params_Grad,scoring='accuracy',cv=5,return_train_score=True)\n",
    "\n",
    "Grad_Grid_OF.fit(data,y)\n",
    "print_best(Grad_Grid_OF)\n",
    "\n",
    "Forest_Grid_OF.fit(data,y)\n",
    "print_best(Forest_Grid_OF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest_pred_OF = pd.Series(Forest_Grid_OF.predict(test), index=test.index, name='Survived')\n",
    "Grad_pred_OF = pd.Series(Grad_Grid_OF.predict(test), index=test.index, name='Survived')\n",
    "\n",
    "print(metrics.confusion_matrix(y,Forest_Grid_OF.predict(data)))\n",
    "print(metrics.confusion_matrix(y,Grad_Grid_OF.predict(data)))\n",
    "\n",
    "\n",
    "Forest_pred_OF.to_csv('Predictions/Forest_Pred_OF_1.csv')\n",
    "Grad_pred_OF.to_csv('Predictions/Grad_Pred_OF_1.csv')\n",
    "\n",
    "\n",
    "# Confusion Matrix:\n",
    "#    | 0  | 1  |\n",
    "#  0 | TN | FN |\n",
    "#  1 | FP | TP |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest_pred_NR = pd.Series(Forest_Grid_NR.predict(test), index=test.index, name='Survived')\n",
    "Grad_pred_NR = pd.Series(Grad_Grid_NR.predict(test), index=test.index, name='Survived')\n",
    "\n",
    "print(metrics.confusion_matrix(y,Forest_Grid_NR.predict(data)))\n",
    "print(metrics.confusion_matrix(y,Grad_Grid_NR.predict(data)))\n",
    "\n",
    "Forest_pred_NR.to_csv('Predictions/Forest_Pred_NR_1.csv')\n",
    "Grad_pred_NR.to_csv('Predictions/Grad_Pred_NR_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.389986Z",
     "start_time": "2021-09-20T11:31:26.389951Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "params_Grad_f1 = dict(Gradient__n_estimators = [100,400,600],\n",
    "                   Gradient__max_depth=[2,5], \n",
    "                   Gradient__random_state=[42],\n",
    "                   Gradient__learning_rate=[0.2,0.1,0.05])\n",
    "\n",
    "# params_Grad_f1 = dict(Gradient__n_estimators = [400],\n",
    "#                    Gradient__max_depth=[2], \n",
    "#                    Gradient__random_state=[42],\n",
    "#                    Gradient__learning_rate=[0.1])\n",
    "\n",
    "params_Frst_f1 = dict(Forest__n_estimators=[200,500,700],\n",
    "                   Forest__max_depth=[None,6,9,12],\n",
    "                   Forest__random_state=[42])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7591260150442718 {'Gradient__learning_rate': 0.1, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7551045173645473 {'Forest__max_depth': 12, 'Forest__n_estimators': 700, 'Forest__random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Grad_Grid_f1 = GridSearchCV(Pipe_Grad,param_grid=params_Grad_f1,scoring='f1',cv=5,verbose=3,n_jobs=1)\n",
    "Forest_Grid_f1 = GridSearchCV(Pipe_Forest,param_grid=params_Frst_f1,scoring='f1',cv=5,verbose=3,n_jobs=1)\n",
    "\n",
    "sys.stdout = open(1, 'w')\n",
    "Grad_Grid_f1.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(Grad_Grid_f1)\n",
    "\n",
    "sys.stdout = open(1, 'w')\n",
    "Forest_Grid_f1.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(Forest_Grid_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[517  32]\n",
      " [ 57 285]]\n",
      "[[543   6]\n",
      " [ 27 315]]\n"
     ]
    }
   ],
   "source": [
    "Grad_pred_f1 = pd.Series(Grad_Grid_f1.predict(test), index=test.index, name='Survived')\n",
    "Forest_pred_f1 = pd.Series(Forest_Grid_f1.predict(test), index=test.index, name='Survived')\n",
    "\n",
    "print(metrics.confusion_matrix(y,Grad_Grid_f1.predict(data)))\n",
    "print(metrics.confusion_matrix(y,Forest_Grid_f1.predict(data)))\n",
    "\n",
    "\n",
    "Grad_pred_f1.to_csv('Predictions/Grad_Pred_f1.csv')\n",
    "Forest_pred_f1.to_csv('Predictions/Forest_Pred_f1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.393001Z",
     "start_time": "2021-09-20T11:31:26.392975Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Tree = tree.DecisionTreeClassifier(random_state=32)\n",
    "Pipe_Tree = Pipeline([\n",
    "    ('Preprocessing', Preprocess),\n",
    "    ('Tree', Tree)\n",
    "])\n",
    "\n",
    "params_Tree = dict(Tree__max_depth = [None],\n",
    "                   Tree__splitter = ['best','random'],\n",
    "                   Tree__min_samples_split = range(2,4),\n",
    "                   Tree__min_samples_leaf = range(1,4),\n",
    "                   Tree__max_leaf_nodes = [None] + list(range(150,300,50))\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7534598724095104 {'Tree__max_depth': None, 'Tree__max_leaf_nodes': 200, 'Tree__min_samples_leaf': 2, 'Tree__min_samples_split': 2, 'Tree__splitter': 'random'}\n",
      "[[521  28]\n",
      " [ 76 266]]\n"
     ]
    }
   ],
   "source": [
    "Tree_Grid = GridSearchCV(Pipe_Tree,param_grid=params_Tree,scoring='f1',cv=10,verbose=3)\n",
    "\n",
    "sys.stdout = open(1, 'w')\n",
    "Tree_Grid.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(Tree_Grid)\n",
    "print(metrics.confusion_matrix(y,Tree_Grid.predict(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.395274Z",
     "start_time": "2021-09-20T11:31:26.395259Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=32)\n",
    "Pipe_logreg = Pipeline([\n",
    "    ('Preprocessing', Preprocess),\n",
    "    ('logreg', logreg)\n",
    "])\n",
    "\n",
    "params_logreg = dict(logreg__penalty = ['l1','l2'],\n",
    "                     logreg__solver = ['liblinear'],\n",
    "                     logreg__max_iter = [100,125,75],\n",
    "                     logreg__C = np.arange(1,2,0.05),\n",
    "                     logreg__class_weight = ['balanced',None]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734546590750368 {'logreg__C': 1.1, 'logreg__class_weight': 'balanced', 'logreg__max_iter': 100, 'logreg__penalty': 'l1', 'logreg__solver': 'liblinear'}\n",
      "[[437 112]\n",
      " [ 73 269]]\n"
     ]
    }
   ],
   "source": [
    "logreg_Grid = GridSearchCV(Pipe_logreg,param_grid=params_logreg,scoring='f1',cv=10,verbose=3)\n",
    "\n",
    "sys.stdout = open(1, 'w')\n",
    "logreg_Grid.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(logreg_Grid)\n",
    "print(metrics.confusion_matrix(y,logreg_Grid.predict(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.396721Z",
     "start_time": "2021-09-20T11:31:26.396695Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Extra_For = ExtraTreesClassifier(warm_start=True,random_state=1)\n",
    "Pipe_Extra = Pipeline([\n",
    "    ('Preprocessing', Preprocess),\n",
    "    ('Extra', Extra_For)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.400664Z",
     "start_time": "2021-09-20T11:31:26.400635Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "params_Extra = dict(Extra__n_estimators = [50,100,200],\n",
    "                    Extra__max_depth = [None],\n",
    "                    Extra__class_weight = [None],\n",
    "                    Extra__ccp_alpha = [0.0]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7321402121164768 {'Extra__ccp_alpha': 0.0, 'Extra__class_weight': None, 'Extra__max_depth': None, 'Extra__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "sys.stdout = open(1, 'w')\n",
    "Extra_Grid_f1 = GridSearchCV(Pipe_Extra,param_grid=params_Extra,scoring='f1',cv=10,n_jobs=1,verbose=3)\n",
    "Extra_Grid_f1.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(Extra_Grid_f1)\n",
    "print(metrics.confusion_matrix(y,Extra_Grid_f1.predict(data)))\n",
    "pd.Series(Extra_Grid_f1.predict(test), index=test.index, name='Survived').to_csv('Predictions/Extra_Pred_f1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.402689Z",
     "start_time": "2021-09-20T11:31:26.402675Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Ada = AdaBoostClassifier(random_state=1,base_estimator = tree.DecisionTreeClassifier(random_state=1))\n",
    "Pipe_Ada = Pipeline([\n",
    "    ('Preprocessing', Preprocess),\n",
    "    ('Ada', Ada)\n",
    "])\n",
    "# possible models for Ada:\n",
    "# ExtraTrees\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.403990Z",
     "start_time": "2021-09-20T11:31:26.403968Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "params_Ada = dict(\n",
    "                  Ada__n_estimators = [50,100,200]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744563123023356 {'Ada__n_estimators': 50}\n",
      "[[539  10]\n",
      " [  7 335]]\n"
     ]
    }
   ],
   "source": [
    "sys.stdout = open(1, 'w')\n",
    "Ada_Grid_f1 = GridSearchCV(Pipe_Ada,param_grid=params_Ada,cv=10,verbose=3,scoring='f1')\n",
    "Ada_Grid_f1.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(Ada_Grid_f1)\n",
    "print(metrics.confusion_matrix(y,Ada_Grid_f1.predict(data)))\n",
    "pd.Series(Ada_Grid_f1.predict(test), index=test.index, name='Survived').to_csv('Predictions/Ada_Pred_f1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "init_cell": true
   },
   "source": [
    "## Bests models: \n",
    "1. GradientBoosting (f1)\n",
    "2. RandomForest (f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to feature engineering\n",
    "Our features should include these facts:\n",
    "1. Kids and teens have a higher chance of surviving\n",
    "2. People with family have a higher chance of surviving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.406039Z",
     "start_time": "2021-09-20T11:31:26.406026Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Age'] = Nmrcl_trns.fit_transform(data[['Age']])\n",
    "data['Has_Someone'] = Binarizer(threshold=0.9).transform([data['Parch'] + data['SibSp']])[0]\n",
    "data['Has_SibSp'] = Binarizer(threshold=0.9).transform([data['SibSp']])[0]\n",
    "data['Under_17'] = 1 - Binarizer(threshold=17).transform([(data['Age'])])[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.408426Z",
     "start_time": "2021-09-20T11:31:26.408400Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "test['Age'] = Nmrcl_trns.fit_transform(test[['Age']])\n",
    "test['Has_Someone'] = Binarizer(threshold=0.9).transform([test['Parch'] + test['SibSp']])[0]\n",
    "test['Has_SibSp'] = Binarizer(threshold=0.9).transform([test['SibSp']])[0]\n",
    "test['Under_17'] = 1 - Binarizer(threshold=17).transform([(test['Age'])])[0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.409657Z",
     "start_time": "2021-09-20T11:31:26.409634Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Feature_Pairs = [\n",
    "    (['Sex','Pclass','Embarked'],['SibSp','Age','Fare']),\n",
    "    (['Sex','Pclass','Embarked','Under_17','Has_SibSp'],['Fare']),\n",
    "    (['Sex','Pclass','Embarked','Under_17','Has_SibSp'],[]),\n",
    "    (['Sex','Pclass','Embarked','Has_SibSp'],['Age']),\n",
    "    (['Sex','Pclass','Embarked','Under_17','Has_Someone'],[]),\n",
    "    (['Sex','Pclass','SibSp','Embarked'],['Age','Fare']),\n",
    "    (['Sex','Pclass','SibSp','Embarked','Under_17','Has_Someone'],['Age','Fare']),\n",
    "    (['Sex','Pclass','Embarked','Under_17'],['SibSp','Age','Fare']),\n",
    "]\n",
    "\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7702513487952218 {'Gradient__learning_rate': 0.05, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 600, 'Gradient__random_state': 42}\n",
      "0.7731677336618445 {'Forest__max_depth': 9, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked'], ['SibSp', 'Age', 'Fare'])\n",
      "0.7732873120586929 {'Gradient__learning_rate': 0.1, 'Gradient__max_depth': 5, 'Gradient__n_estimators': 100, 'Gradient__random_state': 42}\n",
      "0.7556297083572934 {'Forest__max_depth': 9, 'Forest__n_estimators': 500, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Under_17', 'Has_SibSp'], ['Fare'])\n"
     ]
    }
   ],
   "source": [
    "for pair in Feature_Pairs[0:2]:\n",
    "    Preprocess2 = ColumnTransformer([('Categorical_cols', Ctgrcl_trns,pair[0]),\n",
    "                                 ('Numrecial_cols',Nmrcl_trns,pair[1])])\n",
    "    \n",
    "    Grad_Fin = GradientBoostingClassifier(warm_start=True)\n",
    "    Pipe_Grad_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Gradient', Gradient)\n",
    "    ])\n",
    "\n",
    "    Forest_Fin = RandomForestClassifier(warm_start=True)\n",
    "    Pipe_Forest_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Forest', Forest)\n",
    "    ])\n",
    "    \n",
    "    Grad_Grid_Fin = GridSearchCV(Pipe_Grad_Fin,param_grid=params_Grad_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "    Forest_Grid_Fin = GridSearchCV(Pipe_Forest_Fin,param_grid=params_Frst_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Grad_Grid_Fin.fit(data,y)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append([print_best(Grad_Grid_Fin,Prints=False)])\n",
    "    \n",
    "    print_best(Grad_Grid_Fin)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Forest_Grid_Fin.fit(data,y)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append([print_best(Forest_Grid_Fin,Prints=False)])\n",
    "\n",
    "    print_best(Forest_Grid_Fin)\n",
    "    print(\"\\n\",pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7320755603515294 {'Gradient__learning_rate': 0.1, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7216048015283008 {'Forest__max_depth': 6, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Under_17', 'Has_SibSp'], [])\n",
      "0.7549350622890174 {'Gradient__learning_rate': 0.2, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7447045928248592 {'Forest__max_depth': 6, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Has_SibSp'], ['Age'])\n",
      "0.7266765437720577 {'Gradient__learning_rate': 0.05, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7142252496161967 {'Forest__max_depth': None, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Under_17', 'Has_Someone'], [])\n",
      "0.7697356668170433 {'Gradient__learning_rate': 0.1, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7693101636996904 {'Forest__max_depth': 9, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'SibSp', 'Embarked'], ['Age', 'Fare'])\n",
      "0.7688505877991048 {'Gradient__learning_rate': 0.1, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7600273193307135 {'Forest__max_depth': 9, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'SibSp', 'Embarked', 'Under_17', 'Has_Someone'], ['Age', 'Fare'])\n"
     ]
    }
   ],
   "source": [
    "for pair in Feature_Pairs[2:-1]:\n",
    "    Preprocess2 = ColumnTransformer([('Categorical_cols', Ctgrcl_trns,pair[0]),\n",
    "                                 ('Numrecial_cols',Nmrcl_trns,pair[1])])\n",
    "    \n",
    "    Grad_Fin = GradientBoostingClassifier(warm_start=True)\n",
    "    Pipe_Grad_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Gradient', Gradient)\n",
    "    ])\n",
    "\n",
    "    Forest_Fin = RandomForestClassifier(warm_start=True)\n",
    "    Pipe_Forest_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Forest', Forest)\n",
    "    ])\n",
    "    \n",
    "    Grad_Grid_Fin = GridSearchCV(Pipe_Grad_Fin,param_grid=params_Grad_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "    Forest_Grid_Fin = GridSearchCV(Pipe_Forest_Fin,param_grid=params_Frst_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Grad_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append([print_best(Grad_Grid_Fin,Prints=False)])\n",
    "\n",
    "    print_best(Grad_Grid_Fin)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Forest_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append([print_best(Forest_Grid_Fin,Prints=False)])\n",
    "\n",
    "    print_best(Forest_Grid_Fin)\n",
    "    print(\"\\n\",pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7702513487952218 {'Gradient__learning_rate': 0.05, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 600, 'Gradient__random_state': 42}\n",
      "0.7710090271179103 {'Forest__max_depth': 12, 'Forest__n_estimators': 500, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Under_17'], ['SibSp', 'Age', 'Fare'])\n"
     ]
    }
   ],
   "source": [
    "for pair in [Feature_Pairs[-1]]:\n",
    "    Preprocess2 = ColumnTransformer([('Categorical_cols', Ctgrcl_trns,pair[0]),\n",
    "                                 ('Numrecial_cols',Nmrcl_trns,pair[1])])\n",
    "    \n",
    "    Grad_Fin = GradientBoostingClassifier(warm_start=True)\n",
    "    Pipe_Grad_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Gradient', Gradient)\n",
    "    ])\n",
    "\n",
    "    Forest_Fin = RandomForestClassifier(warm_start=True)\n",
    "    Pipe_Forest_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Forest', Forest)\n",
    "    ])\n",
    "    \n",
    "    Grad_Grid_Fin = GridSearchCV(Pipe_Grad_Fin,param_grid=params_Grad_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "    Forest_Grid_Fin = GridSearchCV(Pipe_Forest_Fin,param_grid=params_Frst_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Grad_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append(print_best(Grad_Grid_Fin,Prints=False))\n",
    "\n",
    "    print_best(Grad_Grid_Fin)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Forest_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append([print_best(Forest_Grid_Fin,Prints=False)])\n",
    "\n",
    "    print_best(Forest_Grid_Fin)\n",
    "    print(\"\\n\",pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.411486Z",
     "start_time": "2021-09-20T11:31:26.411470Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Best_Pairs = [(['Sex', 'Pclass', 'Embarked'], ['SibSp', 'Age', 'Fare']),\n",
    "              (['Sex', 'Pclass', 'Embarked'], ['Parch','SibSp', 'Age', 'Fare'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T11:31:26.413063Z",
     "start_time": "2021-09-20T11:31:26.413030Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "params_Grad_Fin = [\n",
    "    dict(Gradient__n_estimators = [400,600,700],\n",
    "         Gradient__max_depth=[2,3], \n",
    "         Gradient__random_state=[42],\n",
    "         Gradient__learning_rate=[0.1,0.05]),\n",
    "    dict(Gradient__n_estimators = [100,200],\n",
    "         Gradient__max_depth=[8,9,10,12], \n",
    "         Gradient__random_state=[42],\n",
    "         Gradient__learning_rate=[0.1,0.05])\n",
    "                  ]\n",
    "\n",
    "\n",
    "params_Frst_Fin = dict(Forest__n_estimators=[200,350,500],\n",
    "                   Forest__max_depth=[None,8,9,10],\n",
    "                   Forest__random_state=[42])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7702513487952218 {'Gradient__learning_rate': 0.05, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 600, 'Gradient__random_state': 42}\n",
      "[[519  30]\n",
      " [ 66 276]]\n",
      "0.7731677336618445 {'Forest__max_depth': 9, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "[[538  11]\n",
      " [ 44 298]]\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked'], ['SibSp', 'Age', 'Fare'])\n",
      "0.7603701395235238 {'Gradient__learning_rate': 0.05, 'Gradient__max_depth': 9, 'Gradient__n_estimators': 100, 'Gradient__random_state': 42}\n",
      "[[530  19]\n",
      " [ 49 293]]\n",
      "0.7608696728957778 {'Forest__max_depth': 8, 'Forest__n_estimators': 500, 'Forest__random_state': 42}\n",
      "[[527  22]\n",
      " [ 71 271]]\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Under_17', 'Has_SibSp'], ['Fare'])\n"
     ]
    }
   ],
   "source": [
    "for index,pair in enumerate(Best_Pairs):\n",
    "    Preprocess2 = ColumnTransformer([('Categorical_cols', Ctgrcl_trns,pair[0]),\n",
    "                                 ('Numrecial_cols',Nmrcl_trns,pair[1])])\n",
    "    \n",
    "    Grad_Fin = GradientBoostingClassifier(warm_start=True)\n",
    "    Pipe_Grad_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Gradient', Gradient)\n",
    "    ])\n",
    "\n",
    "    Forest_Fin = RandomForestClassifier(warm_start=True)\n",
    "    Pipe_Forest_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Forest', Forest)\n",
    "    ])\n",
    "    \n",
    "    Grad_Grid_Fin = GridSearchCV(Pipe_Grad_Fin,param_grid=params_Grad_Fin[index],scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "    Forest_Grid_Fin = GridSearchCV(Pipe_Forest_Fin,param_grid=params_Frst_Fin,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Grad_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append(print_best(Grad_Grid_Fin,Prints=False))\n",
    "\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print(metrics.confusion_matrix(y,Grad_Grid_Fin.predict(data)))\n",
    "    pd.Series(Grad_Grid_Fin.predict(test), index=test.index, name='Survived'\n",
    "             ).to_csv('Predictions/Best_Pred_Grad_{}.csv'.format(index + 1))\n",
    "    \n",
    "    sys.stdout = open(1, 'w')\n",
    "    Forest_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append(print_best(Forest_Grid_Fin,Prints=False))\n",
    "\n",
    "    print_best(Forest_Grid_Fin)\n",
    "    print(metrics.confusion_matrix(y,Forest_Grid_Fin.predict(data)))\n",
    "    pd.Series(Forest_Grid_Fin.predict(test), index=test.index, name='Survived'\n",
    "             ).to_csv('Predictions/Best_Pred_Forest_{}.csv'.format(index + 1))\n",
    "    \n",
    "    print(\"\\n\",pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ctgrcl_Best = make_pipeline(SimpleImputer(strategy='most_frequent'),OneHotEncoder(),)\n",
    "Nmrcl_Best = \n",
    "for index,pair in enumerate(Best_Pairs):\n",
    "    Preprocess3 = ColumnTransformer([('Categorical_cols', Ctgrcl_Best,pair[0]),\n",
    "                                 ('Numrecial_cols',Nmrcl_Best,pair[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.45px",
    "left": "1167px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
