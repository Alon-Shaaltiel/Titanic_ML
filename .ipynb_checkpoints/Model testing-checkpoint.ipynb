{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# TODOs:\n",
    "#     1. Make categorical and numerical datasets\n",
    "#     2. Learn how to handle each type of dataset\n",
    "#     3. Impute missing data\n",
    "#     4. Make different piplines for the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if str(type(sys.stdout)) == \"<class 'ipykernel.iostream.OutStream'>\":\n",
    "    saved_std = sys.stdout\n",
    "else:\n",
    "    sys.stdout = saved_std\n",
    "\n",
    "sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Binarizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n",
    "                              AdaBoostClassifier,ExtraTreesClassifier)\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "y = data['Survived']\n",
    "data.drop(['Name','Ticket','Cabin','Survived'],axis=1,inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "test.drop(['Name','Cabin','Ticket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Categorical_cols = ['Pclass','Embarked','Sex','SibSp']\n",
    "Numerical_cols = ['Fare','Age']\n",
    "\n",
    "Ctgrcl_trns = make_pipeline(SimpleImputer(strategy='most_frequent'),OneHotEncoder())\n",
    "\n",
    "# Sex: ['male','female','male','other']\n",
    "# OHE: [[1,0,1,0],[0,1,0,0],[0,0,0,1]]\n",
    "\n",
    "Nmrcl_trns = make_pipeline(SimpleImputer(strategy='mean'))\n",
    "Preprocess = ColumnTransformer([('Categorical_cols', Ctgrcl_trns,Categorical_cols),\n",
    "                                ('Numrecial_cols',Nmrcl_trns,Numerical_cols)])\n",
    "\n",
    "Gradient = GradientBoostingClassifier(warm_start=True)\n",
    "Pipe_Grad = Pipeline([\n",
    "    ('Preprocessing', Preprocess),\n",
    "    ('Gradient', Gradient)\n",
    "])\n",
    "\n",
    "Forest = RandomForestClassifier(warm_start=True)\n",
    "Pipe_Forest = Pipeline([\n",
    "    ('Preprocessing', Preprocess),\n",
    "    ('Forest', Forest)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "params_Frst = dict(Forest__n_estimators=[50,100,200,300,500],\n",
    "                   Forest__max_depth=[7,8,9,None],\n",
    "                   Forest__random_state=[11])\n",
    "\n",
    "params_Grad = dict(Gradient__n_estimators = [100,200,300,400,500],\n",
    "                   Gradient__max_depth=range(1,4), \n",
    "                   Gradient__random_state=[12],\n",
    "                   Gradient__learning_rate=[0.1,0.05,0.01])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def print_best(Grid,Prints = True):\n",
    "    if Prints:\n",
    "        print(Grid.best_score_,Grid.best_params_)\n",
    "    if not Prints:\n",
    "        return [Grid.best_score_,Grid.best_params_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest_Grid_NR = GridSearchCV(Pipe_Forest,param_grid=params_Frst,scoring='f1',cv=10,return_train_score=True)\n",
    "\n",
    "Grad_Grid_NR = GridSearchCV(Pipe_Grad,param_grid=params_Grad,scoring='roc_auc',cv=10,return_train_score=True)\n",
    "\n",
    "Grad_Grid_NR.fit(data,y)\n",
    "print_best(Grad_Grid_NR)\n",
    "\n",
    "Forest_Grid_NR.fit(data,y)\n",
    "print_best(Forest_Grid_NR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest_Grid_OF = GridSearchCV(Pipe_Forest,param_grid=params_Frst,scoring='accuracy',cv=5,return_train_score=True)\n",
    "Grad_Grid_OF = GridSearchCV(Pipe_Grad,param_grid=params_Grad,scoring='accuracy',cv=5,return_train_score=True)\n",
    "\n",
    "Grad_Grid_OF.fit(data,y)\n",
    "print_best(Grad_Grid_OF)\n",
    "\n",
    "Forest_Grid_OF.fit(data,y)\n",
    "print_best(Forest_Grid_OF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest_pred_OF = pd.Series(Forest_Grid_OF.predict(test), index=test.index, name='Survived')\n",
    "Grad_pred_OF = pd.Series(Grad_Grid_OF.predict(test), index=test.index, name='Survived')\n",
    "\n",
    "print(metrics.confusion_matrix(y,Forest_Grid_OF.predict(data)))\n",
    "print(metrics.confusion_matrix(y,Grad_Grid_OF.predict(data)))\n",
    "\n",
    "\n",
    "Forest_pred_OF.to_csv('Predictions/Forest_Pred_OF_1.csv')\n",
    "Grad_pred_OF.to_csv('Predictions/Grad_Pred_OF_1.csv')\n",
    "\n",
    "\n",
    "# Confusion Matrix:\n",
    "#    | 0  | 1  |\n",
    "#  0 | TN | FN |\n",
    "#  1 | FP | TP |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest_pred_NR = pd.Series(Forest_Grid_NR.predict(test), index=test.index, name='Survived')\n",
    "Grad_pred_NR = pd.Series(Grad_Grid_NR.predict(test), index=test.index, name='Survived')\n",
    "\n",
    "print(metrics.confusion_matrix(y,Forest_Grid_NR.predict(data)))\n",
    "print(metrics.confusion_matrix(y,Grad_Grid_NR.predict(data)))\n",
    "\n",
    "Forest_pred_NR.to_csv('Predictions/Forest_Pred_NR_1.csv')\n",
    "Grad_pred_NR.to_csv('Predictions/Grad_Pred_NR_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "params_Grad_f1 = dict(Gradient__n_estimators = [100,400,600],\n",
    "                   Gradient__max_depth=[2,5], \n",
    "                   Gradient__random_state=[42],\n",
    "                   Gradient__learning_rate=[0.2,0.1,0.05])\n",
    "\n",
    "# params_Grad_f1 = dict(Gradient__n_estimators = [400],\n",
    "#                    Gradient__max_depth=[2], \n",
    "#                    Gradient__random_state=[42],\n",
    "#                    Gradient__learning_rate=[0.1])\n",
    "\n",
    "params_Frst_f1 = dict(Forest__n_estimators=[200,500,700],\n",
    "                   Forest__max_depth=[None,6,9,12],\n",
    "                   Forest__random_state=[42])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7591260150442718 {'Gradient__learning_rate': 0.1, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7551045173645473 {'Forest__max_depth': 12, 'Forest__n_estimators': 700, 'Forest__random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Grad_Grid_f1 = GridSearchCV(Pipe_Grad,param_grid=params_Grad_f1,scoring='f1',cv=5,verbose=3,n_jobs=1)\n",
    "Forest_Grid_f1 = GridSearchCV(Pipe_Forest,param_grid=params_Frst_f1,scoring='f1',cv=5,verbose=3,n_jobs=1)\n",
    "\n",
    "sys.stdout = open(1, 'w')\n",
    "Grad_Grid_f1.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(Grad_Grid_f1)\n",
    "\n",
    "sys.stdout = open(1, 'w')\n",
    "Forest_Grid_f1.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(Forest_Grid_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[517  32]\n",
      " [ 57 285]]\n",
      "[[543   6]\n",
      " [ 27 315]]\n"
     ]
    }
   ],
   "source": [
    "Grad_pred_f1 = pd.Series(Grad_Grid_f1.predict(test), index=test.index, name='Survived')\n",
    "Forest_pred_f1 = pd.Series(Forest_Grid_f1.predict(test), index=test.index, name='Survived')\n",
    "\n",
    "print(metrics.confusion_matrix(y,Grad_Grid_f1.predict(data)))\n",
    "print(metrics.confusion_matrix(y,Forest_Grid_f1.predict(data)))\n",
    "\n",
    "\n",
    "Grad_pred_f1.to_csv('Predictions/Grad_Pred_f1.csv')\n",
    "Forest_pred_f1.to_csv('Predictions/Forest_Pred_f1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Tree = tree.DecisionTreeClassifier(random_state=32)\n",
    "Pipe_Tree = Pipeline([\n",
    "    ('Preprocessing', Preprocess),\n",
    "    ('Tree', Tree)\n",
    "])\n",
    "\n",
    "params_Tree = dict(Tree__max_depth = [None],\n",
    "                   Tree__splitter = ['best','random'],\n",
    "                   Tree__min_samples_split = range(2,4),\n",
    "                   Tree__min_samples_leaf = range(1,4),\n",
    "                   Tree__max_leaf_nodes = [None] + list(range(150,300,50))\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7534598724095104 {'Tree__max_depth': None, 'Tree__max_leaf_nodes': 200, 'Tree__min_samples_leaf': 2, 'Tree__min_samples_split': 2, 'Tree__splitter': 'random'}\n",
      "[[521  28]\n",
      " [ 76 266]]\n"
     ]
    }
   ],
   "source": [
    "Tree_Grid = GridSearchCV(Pipe_Tree,param_grid=params_Tree,scoring='f1',cv=10,verbose=3)\n",
    "\n",
    "sys.stdout = open(1, 'w')\n",
    "Tree_Grid.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(Tree_Grid)\n",
    "print(metrics.confusion_matrix(y,Tree_Grid.predict(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=32)\n",
    "Pipe_logreg = Pipeline([\n",
    "    ('Preprocessing', Preprocess),\n",
    "    ('logreg', logreg)\n",
    "])\n",
    "\n",
    "params_logreg = dict(logreg__penalty = ['l1','l2'],\n",
    "                     logreg__solver = ['liblinear'],\n",
    "                     logreg__max_iter = [100,125,75],\n",
    "                     logreg__C = np.arange(1,2,0.05),\n",
    "                     logreg__class_weight = ['balanced',None]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734546590750368 {'logreg__C': 1.1, 'logreg__class_weight': 'balanced', 'logreg__max_iter': 100, 'logreg__penalty': 'l1', 'logreg__solver': 'liblinear'}\n",
      "[[437 112]\n",
      " [ 73 269]]\n"
     ]
    }
   ],
   "source": [
    "logreg_Grid = GridSearchCV(Pipe_logreg,param_grid=params_logreg,scoring='f1',cv=10,verbose=3)\n",
    "\n",
    "sys.stdout = open(1, 'w')\n",
    "logreg_Grid.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(logreg_Grid)\n",
    "print(metrics.confusion_matrix(y,logreg_Grid.predict(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Extra_For = ExtraTreesClassifier(warm_start=True,random_state=1)\n",
    "Pipe_Extra = Pipeline([\n",
    "    ('Preprocessing', Preprocess),\n",
    "    ('Extra', Extra_For)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "params_Extra = dict(Extra__n_estimators = [50,100,200],\n",
    "                    Extra__max_depth = [None],\n",
    "                    Extra__class_weight = [None],\n",
    "                    Extra__ccp_alpha = [0.0]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7321402121164768 {'Extra__ccp_alpha': 0.0, 'Extra__class_weight': None, 'Extra__max_depth': None, 'Extra__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "sys.stdout = open(1, 'w')\n",
    "Extra_Grid_f1 = GridSearchCV(Pipe_Extra,param_grid=params_Extra,scoring='f1',cv=10,n_jobs=1,verbose=3)\n",
    "Extra_Grid_f1.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(Extra_Grid_f1)\n",
    "print(metrics.confusion_matrix(y,Extra_Grid_f1.predict(data)))\n",
    "pd.Series(Extra_Grid_f1.predict(test), index=test.index, name='Survived').to_csv('Predictions/Extra_Pred_f1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Ada = AdaBoostClassifier(random_state=1,base_estimator = tree.DecisionTreeClassifier(random_state=1))\n",
    "Pipe_Ada = Pipeline([\n",
    "    ('Preprocessing', Preprocess),\n",
    "    ('Ada', Ada)\n",
    "])\n",
    "# possible models for Ada:\n",
    "# ExtraTrees\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "params_Ada = dict(\n",
    "                  Ada__n_estimators = [50,100,200]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744563123023356 {'Ada__n_estimators': 50}\n",
      "[[539  10]\n",
      " [  7 335]]\n"
     ]
    }
   ],
   "source": [
    "sys.stdout = open(1, 'w')\n",
    "Ada_Grid_f1 = GridSearchCV(Pipe_Ada,param_grid=params_Ada,cv=10,verbose=3,scoring='f1')\n",
    "Ada_Grid_f1.fit(data,y)\n",
    "print('Done with grid :)')\n",
    "sys.stdout = saved_std\n",
    "\n",
    "print_best(Ada_Grid_f1)\n",
    "print(metrics.confusion_matrix(y,Ada_Grid_f1.predict(data)))\n",
    "pd.Series(Ada_Grid_f1.predict(test), index=test.index, name='Survived').to_csv('Predictions/Ada_Pred_f1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "init_cell": true
   },
   "source": [
    "## Bests models: \n",
    "1. GradientBoosting (f1)\n",
    "2. RandomForest (f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to feature engineering\n",
    "Our features should include these facts:\n",
    "1. Kids and teens have a higher chance of surviving\n",
    "2. People with family have a higher chance of surviving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Age'] = Nmrcl_trns.fit_transform(data[['Age']])\n",
    "data['Has_Someone'] = Binarizer(threshold=0.9).transform([data['Parch'] + data['SibSp']])[0]\n",
    "data['Has_SibSp'] = Binarizer(threshold=0.9).transform([data['SibSp']])[0]\n",
    "data['Under_17'] = 1 - Binarizer(threshold=17).transform([(data['Age'])])[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "test['Age'] = Nmrcl_trns.fit_transform(test[['Age']])\n",
    "test['Has_Someone'] = Binarizer(threshold=0.9).transform([test['Parch'] + test['SibSp']])[0]\n",
    "test['Has_SibSp'] = Binarizer(threshold=0.9).transform([test['SibSp']])[0]\n",
    "test['Under_17'] = 1 - Binarizer(threshold=17).transform([(test['Age'])])[0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Feature_Pairs = [\n",
    "    (['Sex','Pclass','Embarked'],['SibSp','Age','Fare']),\n",
    "    (['Sex','Pclass','Embarked','Under_17','Has_SibSp'],['Fare']),\n",
    "    (['Sex','Pclass','Embarked','Under_17','Has_SibSp'],[]),\n",
    "    (['Sex','Pclass','Embarked','Has_SibSp'],['Age']),\n",
    "    (['Sex','Pclass','Embarked','Under_17','Has_Someone'],[]),\n",
    "    (['Sex','Pclass','SibSp','Embarked'],['Age','Fare']),\n",
    "    (['Sex','Pclass','SibSp','Embarked','Under_17','Has_Someone'],['Age','Fare']),\n",
    "    (['Sex','Pclass','Embarked','Under_17'],['SibSp','Age','Fare']),\n",
    "]\n",
    "\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7702513487952218 {'Gradient__learning_rate': 0.05, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 600, 'Gradient__random_state': 42}\n",
      "0.7731677336618445 {'Forest__max_depth': 9, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked'], ['SibSp', 'Age', 'Fare'])\n",
      "0.7732873120586929 {'Gradient__learning_rate': 0.1, 'Gradient__max_depth': 5, 'Gradient__n_estimators': 100, 'Gradient__random_state': 42}\n",
      "0.7556297083572934 {'Forest__max_depth': 9, 'Forest__n_estimators': 500, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Under_17', 'Has_SibSp'], ['Fare'])\n"
     ]
    }
   ],
   "source": [
    "for pair in Feature_Pairs[0:2]:\n",
    "    Preprocess2 = ColumnTransformer([('Categorical_cols', Ctgrcl_trns,pair[0]),\n",
    "                                 ('Numrecial_cols',Nmrcl_trns,pair[1])])\n",
    "    \n",
    "    Grad_Fin = GradientBoostingClassifier(warm_start=True)\n",
    "    Pipe_Grad_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Gradient', Gradient)\n",
    "    ])\n",
    "\n",
    "    Forest_Fin = RandomForestClassifier(warm_start=True)\n",
    "    Pipe_Forest_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Forest', Forest)\n",
    "    ])\n",
    "    \n",
    "    Grad_Grid_Fin = GridSearchCV(Pipe_Grad_Fin,param_grid=params_Grad_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "    Forest_Grid_Fin = GridSearchCV(Pipe_Forest_Fin,param_grid=params_Frst_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Grad_Grid_Fin.fit(data,y)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append([print_best(Grad_Grid_Fin,Prints=False)])\n",
    "    \n",
    "    print_best(Grad_Grid_Fin)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Forest_Grid_Fin.fit(data,y)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append([print_best(Forest_Grid_Fin,Prints=False)])\n",
    "\n",
    "    print_best(Forest_Grid_Fin)\n",
    "    print(\"\\n\",pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7320755603515294 {'Gradient__learning_rate': 0.1, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7216048015283008 {'Forest__max_depth': 6, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Under_17', 'Has_SibSp'], [])\n",
      "0.7549350622890174 {'Gradient__learning_rate': 0.2, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7447045928248592 {'Forest__max_depth': 6, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Has_SibSp'], ['Age'])\n",
      "0.7266765437720577 {'Gradient__learning_rate': 0.05, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7142252496161967 {'Forest__max_depth': None, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Under_17', 'Has_Someone'], [])\n",
      "0.7697356668170433 {'Gradient__learning_rate': 0.1, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7693101636996904 {'Forest__max_depth': 9, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'SibSp', 'Embarked'], ['Age', 'Fare'])\n",
      "0.7688505877991048 {'Gradient__learning_rate': 0.1, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 400, 'Gradient__random_state': 42}\n",
      "0.7600273193307135 {'Forest__max_depth': 9, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'SibSp', 'Embarked', 'Under_17', 'Has_Someone'], ['Age', 'Fare'])\n"
     ]
    }
   ],
   "source": [
    "for pair in Feature_Pairs[2:-1]:\n",
    "    Preprocess2 = ColumnTransformer([('Categorical_cols', Ctgrcl_trns,pair[0]),\n",
    "                                 ('Numrecial_cols',Nmrcl_trns,pair[1])])\n",
    "    \n",
    "    Grad_Fin = GradientBoostingClassifier(warm_start=True)\n",
    "    Pipe_Grad_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Gradient', Gradient)\n",
    "    ])\n",
    "\n",
    "    Forest_Fin = RandomForestClassifier(warm_start=True)\n",
    "    Pipe_Forest_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Forest', Forest)\n",
    "    ])\n",
    "    \n",
    "    Grad_Grid_Fin = GridSearchCV(Pipe_Grad_Fin,param_grid=params_Grad_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "    Forest_Grid_Fin = GridSearchCV(Pipe_Forest_Fin,param_grid=params_Frst_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Grad_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append([print_best(Grad_Grid_Fin,Prints=False)])\n",
    "\n",
    "    print_best(Grad_Grid_Fin)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Forest_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append([print_best(Forest_Grid_Fin,Prints=False)])\n",
    "\n",
    "    print_best(Forest_Grid_Fin)\n",
    "    print(\"\\n\",pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7702513487952218 {'Gradient__learning_rate': 0.05, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 600, 'Gradient__random_state': 42}\n",
      "0.7710090271179103 {'Forest__max_depth': 12, 'Forest__n_estimators': 500, 'Forest__random_state': 42}\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Under_17'], ['SibSp', 'Age', 'Fare'])\n"
     ]
    }
   ],
   "source": [
    "for pair in [Feature_Pairs[-1]]:\n",
    "    Preprocess2 = ColumnTransformer([('Categorical_cols', Ctgrcl_trns,pair[0]),\n",
    "                                 ('Numrecial_cols',Nmrcl_trns,pair[1])])\n",
    "    \n",
    "    Grad_Fin = GradientBoostingClassifier(warm_start=True)\n",
    "    Pipe_Grad_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Gradient', Gradient)\n",
    "    ])\n",
    "\n",
    "    Forest_Fin = RandomForestClassifier(warm_start=True)\n",
    "    Pipe_Forest_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Forest', Forest)\n",
    "    ])\n",
    "    \n",
    "    Grad_Grid_Fin = GridSearchCV(Pipe_Grad_Fin,param_grid=params_Grad_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "    Forest_Grid_Fin = GridSearchCV(Pipe_Forest_Fin,param_grid=params_Frst_f1,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Grad_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append(print_best(Grad_Grid_Fin,Prints=False))\n",
    "\n",
    "    print_best(Grad_Grid_Fin)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Forest_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append([print_best(Forest_Grid_Fin,Prints=False)])\n",
    "\n",
    "    print_best(Forest_Grid_Fin)\n",
    "    print(\"\\n\",pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Best_Pairs = [(['Sex', 'Pclass', 'Embarked'], ['SibSp', 'Age', 'Fare']),\n",
    "              (['Sex', 'Pclass', 'Embarked', 'Under_17', 'Has_SibSp'], ['Fare'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "params_Grad_Fin = [\n",
    "    dict(Gradient__n_estimators = [400,600,700],\n",
    "         Gradient__max_depth=[2,3], \n",
    "         Gradient__random_state=[42],\n",
    "         Gradient__learning_rate=[0.1,0.05]),\n",
    "    dict(Gradient__n_estimators = [100,200],\n",
    "         Gradient__max_depth=[8,9,10,12], \n",
    "         Gradient__random_state=[42],\n",
    "         Gradient__learning_rate=[0.1,0.05])\n",
    "                  ]\n",
    "\n",
    "\n",
    "params_Frst_Fin = dict(Forest__n_estimators=[200,350,500],\n",
    "                   Forest__max_depth=[None,8,9,10],\n",
    "                   Forest__random_state=[42])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7702513487952218 {'Gradient__learning_rate': 0.05, 'Gradient__max_depth': 2, 'Gradient__n_estimators': 600, 'Gradient__random_state': 42}\n",
      "[[519  30]\n",
      " [ 66 276]]\n",
      "0.7731677336618445 {'Forest__max_depth': 9, 'Forest__n_estimators': 200, 'Forest__random_state': 42}\n",
      "[[538  11]\n",
      " [ 44 298]]\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked'], ['SibSp', 'Age', 'Fare'])\n",
      "0.7603701395235238 {'Gradient__learning_rate': 0.05, 'Gradient__max_depth': 9, 'Gradient__n_estimators': 100, 'Gradient__random_state': 42}\n",
      "[[530  19]\n",
      " [ 49 293]]\n",
      "0.7608696728957778 {'Forest__max_depth': 8, 'Forest__n_estimators': 500, 'Forest__random_state': 42}\n",
      "[[527  22]\n",
      " [ 71 271]]\n",
      "\n",
      " (['Sex', 'Pclass', 'Embarked', 'Under_17', 'Has_SibSp'], ['Fare'])\n"
     ]
    }
   ],
   "source": [
    "for index,pair in enumerate(Best_Pairs):\n",
    "    Preprocess2 = ColumnTransformer([('Categorical_cols', Ctgrcl_trns,pair[0]),\n",
    "                                 ('Numrecial_cols',Nmrcl_trns,pair[1])])\n",
    "    \n",
    "    Grad_Fin = GradientBoostingClassifier(warm_start=True)\n",
    "    Pipe_Grad_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Gradient', Gradient)\n",
    "    ])\n",
    "\n",
    "    Forest_Fin = RandomForestClassifier(warm_start=True)\n",
    "    Pipe_Forest_Fin = Pipeline([\n",
    "        ('Preprocessing', Preprocess2),\n",
    "        ('Forest', Forest)\n",
    "    ])\n",
    "    \n",
    "    Grad_Grid_Fin = GridSearchCV(Pipe_Grad_Fin,param_grid=params_Grad_Fin[index],scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "    Forest_Grid_Fin = GridSearchCV(Pipe_Forest_Fin,param_grid=params_Frst_Fin,scoring='f1',cv=10,verbose=10,n_jobs=1)\n",
    "\n",
    "    sys.stdout = open(1, 'w')\n",
    "    Grad_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append(print_best(Grad_Grid_Fin,Prints=False))\n",
    "\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print(metrics.confusion_matrix(y,Grad_Grid_Fin.predict(data)))\n",
    "    pd.Series(Grad_Grid_Fin.predict(test), index=test.index, name='Survived'\n",
    "             ).to_csv('Predictions/Best_Pred_Grad_{}.csv'.format(index + 1))\n",
    "    \n",
    "    sys.stdout = open(1, 'w')\n",
    "    Forest_Grid_Fin.fit(data,y)\n",
    "    print_best(Grad_Grid_Fin)\n",
    "    print('Done with grid :)')\n",
    "    sys.stdout = saved_std\n",
    "    scores.append(print_best(Forest_Grid_Fin,Prints=False))\n",
    "\n",
    "    print_best(Forest_Grid_Fin)\n",
    "    print(metrics.confusion_matrix(y,Forest_Grid_Fin.predict(data)))\n",
    "    pd.Series(Forest_Grid_Fin.predict(test), index=test.index, name='Survived'\n",
    "             ).to_csv('Predictions/Best_Pred_Forest_{}.csv'.format(index + 1))\n",
    "    \n",
    "    print(\"\\n\",pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
